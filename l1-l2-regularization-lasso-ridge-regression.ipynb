{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f862f278",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T10:51:29.813034Z",
     "iopub.status.busy": "2023-09-02T10:51:29.812594Z",
     "iopub.status.idle": "2023-09-02T10:51:30.221840Z",
     "shell.execute_reply": "2023-09-02T10:51:30.220699Z"
    },
    "papermill": {
     "duration": 0.424818,
     "end_time": "2023-09-02T10:51:30.224783",
     "exception": false,
     "start_time": "2023-09-02T10:51:29.799965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# In this notebook we will try to solve the prolem of overfitting by using L1 and L2 regularization technique.\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6ad5d4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841b18b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T10:51:30.246820Z",
     "iopub.status.busy": "2023-09-02T10:51:30.246318Z",
     "iopub.status.idle": "2023-09-02T10:51:30.578140Z",
     "shell.execute_reply": "2023-09-02T10:51:30.576906Z"
    },
    "papermill": {
     "duration": 0.347055,
     "end_time": "2023-09-02T10:51:30.582098",
     "exception": false,
     "start_time": "2023-09-02T10:51:30.235043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('D:\\Coding\\melbourne_housing_analisi\\Melbourne_housing.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece8554a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T10:51:30.605309Z",
     "iopub.status.busy": "2023-09-02T10:51:30.604951Z",
     "iopub.status.idle": "2023-09-02T10:51:30.667748Z",
     "shell.execute_reply": "2023-09-02T10:51:30.666717Z"
    },
    "papermill": {
     "duration": 0.077578,
     "end_time": "2023-09-02T10:51:30.670286",
     "exception": false,
     "start_time": "2023-09-02T10:51:30.592708",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbc540e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T10:51:30.693774Z",
     "iopub.status.busy": "2023-09-02T10:51:30.693415Z",
     "iopub.status.idle": "2023-09-02T10:51:30.700726Z",
     "shell.execute_reply": "2023-09-02T10:51:30.699990Z"
    },
    "papermill": {
     "duration": 0.021273,
     "end_time": "2023-09-02T10:51:30.702866",
     "exception": false,
     "start_time": "2023-09-02T10:51:30.681593",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929cc5f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T10:51:30.727547Z",
     "iopub.status.busy": "2023-09-02T10:51:30.726962Z",
     "iopub.status.idle": "2023-09-02T10:51:30.764008Z",
     "shell.execute_reply": "2023-09-02T10:51:30.762917Z"
    },
    "papermill": {
     "duration": 0.052253,
     "end_time": "2023-09-02T10:51:30.766831",
     "exception": false,
     "start_time": "2023-09-02T10:51:30.714578",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now lets observe our data and try to drop some columns that are not very uselful in our data analysis. I am just dropping some columns\n",
    "# like date, latitute etc that are not very meaningful for our analysis. \n",
    "columns_to_use = ['Suburb', 'Rooms', 'Type', 'Method', 'SellerG', 'Regionname', 'Propertycount', 'Bedroom', 'Bathroom', 'Postcode','Car', 'Price']\n",
    "df_new = df[columns_to_use]\n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04c0341",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T10:51:30.791601Z",
     "iopub.status.busy": "2023-09-02T10:51:30.791232Z",
     "iopub.status.idle": "2023-09-02T10:51:30.798313Z",
     "shell.execute_reply": "2023-09-02T10:51:30.797127Z"
    },
    "papermill": {
     "duration": 0.022298,
     "end_time": "2023-09-02T10:51:30.800716",
     "exception": false,
     "start_time": "2023-09-02T10:51:30.778418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211161a3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T10:51:30.825734Z",
     "iopub.status.busy": "2023-09-02T10:51:30.825356Z",
     "iopub.status.idle": "2023-09-02T10:51:30.858621Z",
     "shell.execute_reply": "2023-09-02T10:51:30.857755Z"
    },
    "papermill": {
     "duration": 0.048829,
     "end_time": "2023-09-02T10:51:30.861038",
     "exception": false,
     "start_time": "2023-09-02T10:51:30.812209",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now lets do some data cleaning\n",
    "df_new.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9cd2588",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T10:51:30.887886Z",
     "iopub.status.busy": "2023-09-02T10:51:30.886830Z",
     "iopub.status.idle": "2023-09-02T10:51:30.928064Z",
     "shell.execute_reply": "2023-09-02T10:51:30.926951Z"
    },
    "papermill": {
     "duration": 0.056996,
     "end_time": "2023-09-02T10:51:30.930406",
     "exception": false,
     "start_time": "2023-09-02T10:51:30.873410",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# so we have several columns with NaN values so we need to handle these columns. We can actually fill some of these column's NaN \n",
    "# values just by 0 and some other columns might need some other treatment based on their nature for example price.\n",
    "# lets first handle the columns where we need to fill only 0.\n",
    "\n",
    "columns_to_fill_0 = ['Car', 'Bathroom', 'Bedroom']\n",
    "df_new[columns_to_fill_0] = df[columns_to_fill_0].fillna(0)\n",
    "df_new = df_new.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "df_new.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40161479",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T10:51:30.957379Z",
     "iopub.status.busy": "2023-09-02T10:51:30.956402Z",
     "iopub.status.idle": "2023-09-02T10:51:31.084065Z",
     "shell.execute_reply": "2023-09-02T10:51:31.082859Z"
    },
    "papermill": {
     "duration": 0.144483,
     "end_time": "2023-09-02T10:51:31.087165",
     "exception": false,
     "start_time": "2023-09-02T10:51:30.942682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now lets fill the columns named landsize and building area with mean of the whole respective columns\n",
    "df_new = df_new.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "# in the buildingArea column there are some infitly large valuea and the model was not training because of that that is why \n",
    "# I had to come back here and drop those inf values as well.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c534d092",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T10:51:31.113741Z",
     "iopub.status.busy": "2023-09-02T10:51:31.113321Z",
     "iopub.status.idle": "2023-09-02T10:51:31.128914Z",
     "shell.execute_reply": "2023-09-02T10:51:31.127865Z"
    },
    "papermill": {
     "duration": 0.031551,
     "end_time": "2023-09-02T10:51:31.131247",
     "exception": false,
     "start_time": "2023-09-02T10:51:31.099696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_new.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfcd82b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T10:51:31.157839Z",
     "iopub.status.busy": "2023-09-02T10:51:31.157470Z",
     "iopub.status.idle": "2023-09-02T10:51:31.265915Z",
     "shell.execute_reply": "2023-09-02T10:51:31.264799Z"
    },
    "papermill": {
     "duration": 0.124658,
     "end_time": "2023-09-02T10:51:31.268362",
     "exception": false,
     "start_time": "2023-09-02T10:51:31.143704",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# now we are good to go with out cleaned data. Now we are going to make dummy variables for our whole dataset.\n",
    "df_new = pd.get_dummies(df_new, drop_first=True) # it is a short cut to avoid dummy variable trap it is just dropping the main column whose dummies we have produced. \n",
    "df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532cf743",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T10:51:31.297947Z",
     "iopub.status.busy": "2023-09-02T10:51:31.296897Z",
     "iopub.status.idle": "2023-09-02T10:51:31.306996Z",
     "shell.execute_reply": "2023-09-02T10:51:31.306163Z"
    },
    "papermill": {
     "duration": 0.02699,
     "end_time": "2023-09-02T10:51:31.309239",
     "exception": false,
     "start_time": "2023-09-02T10:51:31.282249",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = df_new.drop('Price', axis='columns')\n",
    "y = df_new.Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9272e374",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rimozione outlier\n",
    "numeric_cols = df.select_dtypes(include=[\"float\", \"int\"]).columns.tolist()\n",
    "\n",
    "for col in numeric_cols:\n",
    "    Q1 = df[col].quantile(0.2)\n",
    "    Q3 = df[col].quantile(0.8)\n",
    "    IQR = Q3 - Q1\n",
    "    lower, upper = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR\n",
    "\n",
    "    df[col] = np.where(df[col].between(lower, upper), df[col], np.nan)\n",
    "\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a178793e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import StandardScaler\n",
    "\n",
    "\n",
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e3a8d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T10:51:31.337413Z",
     "iopub.status.busy": "2023-09-02T10:51:31.336707Z",
     "iopub.status.idle": "2023-09-02T10:51:32.645281Z",
     "shell.execute_reply": "2023-09-02T10:51:32.644181Z"
    },
    "papermill": {
     "duration": 1.325703,
     "end_time": "2023-09-02T10:51:32.648038",
     "exception": false,
     "start_time": "2023-09-02T10:51:31.322335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now we can jump into our machine learning model and lets first use the train_test_split method\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_scaled, y, train_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaa3a70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T10:51:32.676556Z",
     "iopub.status.busy": "2023-09-02T10:51:32.676167Z",
     "iopub.status.idle": "2023-09-02T10:51:33.564886Z",
     "shell.execute_reply": "2023-09-02T10:51:33.563420Z"
    },
    "papermill": {
     "duration": 0.907452,
     "end_time": "2023-09-02T10:51:33.568906",
     "exception": false,
     "start_time": "2023-09-02T10:51:32.661454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "model = LogisticRegression(solver='liblinear')\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "scores = cross_val_score(model, x_train, y_train, cv=cv, scoring='f1')\n",
    "\n",
    "print(\"F1 Scores:\", scores)\n",
    "print(\"Average F1:\", scores.mean())\n",
    "\n",
    "model.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655bd0f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T10:51:33.629376Z",
     "iopub.status.busy": "2023-09-02T10:51:33.628703Z",
     "iopub.status.idle": "2023-09-02T10:51:33.678555Z",
     "shell.execute_reply": "2023-09-02T10:51:33.677039Z"
    },
    "papermill": {
     "duration": 0.085854,
     "end_time": "2023-09-02T10:51:33.683317",
     "exception": false,
     "start_time": "2023-09-02T10:51:33.597463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.score(x_test, y_test)\n",
    "# Our model is much overfit with the training dataset that its accuracy in negative when we provide it with testing dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d3a3cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T10:51:33.745602Z",
     "iopub.status.busy": "2023-09-02T10:51:33.744907Z",
     "iopub.status.idle": "2023-09-02T10:51:33.820918Z",
     "shell.execute_reply": "2023-09-02T10:51:33.819429Z"
    },
    "papermill": {
     "duration": 0.11206,
     "end_time": "2023-09-02T10:51:33.825686",
     "exception": false,
     "start_time": "2023-09-02T10:51:33.713626",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.score(x_train, y_train) # at the same our model is performing very well with respect to the training datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c3ca76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T10:51:33.891108Z",
     "iopub.status.busy": "2023-09-02T10:51:33.890435Z",
     "iopub.status.idle": "2023-09-02T10:51:42.201122Z",
     "shell.execute_reply": "2023-09-02T10:51:42.199675Z"
    },
    "papermill": {
     "duration": 8.346272,
     "end_time": "2023-09-02T10:51:42.205695",
     "exception": false,
     "start_time": "2023-09-02T10:51:33.859423",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "\n",
    "for a in [0.1, 1, 10, 50]:\n",
    "    model = Lasso(alpha=a)\n",
    "    model.fit(x_train, y_train)\n",
    "    print(a, model.score(x_test, y_test))\n",
    "    print(a, model.score(x_train, y_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347deab9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T10:51:42.379128Z",
     "iopub.status.busy": "2023-09-02T10:51:42.378453Z",
     "iopub.status.idle": "2023-09-02T10:51:42.447652Z",
     "shell.execute_reply": "2023-09-02T10:51:42.446120Z"
    },
    "papermill": {
     "duration": 0.106239,
     "end_time": "2023-09-02T10:51:42.452493",
     "exception": false,
     "start_time": "2023-09-02T10:51:42.346254",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now we will use the L2 regularization tehnique\n",
    "from sklearn.linear_model import Ridge\n",
    "ridge_model = Ridge(alpha=0.1)\n",
    "ridge_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe356544",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T10:51:42.517468Z",
     "iopub.status.busy": "2023-09-02T10:51:42.516781Z",
     "iopub.status.idle": "2023-09-02T10:51:42.749979Z",
     "shell.execute_reply": "2023-09-02T10:51:42.748387Z"
    },
    "papermill": {
     "duration": 0.271033,
     "end_time": "2023-09-02T10:51:42.754738",
     "exception": false,
     "start_time": "2023-09-02T10:51:42.483705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ridge_model.score(x_test,y_test)\n",
    "# after using L2 regularization our model is also much better but it seems that L1 regularization is slightly better then L2 in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea876c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_model.score(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e1a995",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-02T10:51:42.846608Z",
     "iopub.status.busy": "2023-09-02T10:51:42.846185Z",
     "iopub.status.idle": "2023-09-02T10:51:42.866673Z",
     "shell.execute_reply": "2023-09-02T10:51:42.865473Z"
    },
    "papermill": {
     "duration": 0.064028,
     "end_time": "2023-09-02T10:51:42.870482",
     "exception": false,
     "start_time": "2023-09-02T10:51:42.806454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "\n",
    "ela = ElasticNet(alpha=0.1, l1_ratio=0.5)\n",
    "ela.fit(x_train, y_train)\n",
    "ela.score(x_test, y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17.471241,
   "end_time": "2023-09-02T10:51:43.623769",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-09-02T10:51:26.152528",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
